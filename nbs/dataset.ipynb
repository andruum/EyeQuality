{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02236ffa-8bee-4ce8-bcde-48f34d12bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f06b01-3105-4534-b209-68c5b3ccc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "DATASET_PATH = \"/home/tiurin/projects/ExampleProject/Temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d714226a-d67a-4539-8c25-92dee30a6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106a8654-04f4-4803-9424-2877231ef8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def color_feature(image):\n",
    "    return np.mean(image[image>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af827442-116b-48da-8c22-3fae866602e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def moving_average_filter(img, size):\n",
    "    kernel = np.ones((size, size), np.float32) / (size*size)\n",
    "    filtered = cv.filter2D(img, -1, kernel)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e2b67f0-c600-48cd-a973-66f9dba9dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def sobel(image):\n",
    "    \n",
    "    ddepth = cv.CV_16S\n",
    "    scale = 1\n",
    "    delta = 0\n",
    "    \n",
    "    grad_x = cv.Sobel(image, ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv.BORDER_DEFAULT)\n",
    "    grad_y = cv.Sobel(image, ddepth, 0, 1, ksize=3, scale=scale, delta=delta, borderType=cv.BORDER_DEFAULT)\n",
    "    \n",
    "    abs_grad_x = cv.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv.convertScaleAbs(grad_y)\n",
    "    \n",
    "    grad = cv.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1827566-a751-4f65-972e-d8d103b9c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def focus_features(image):\n",
    "    FM1 = np.mean(sobel(image))\n",
    "    \n",
    "    fm2 = np.mean(sobel(moving_average_filter(image, 3)))\n",
    "    FM2 = FM1 - fm2\n",
    "    \n",
    "    fm3 = np.mean(sobel(moving_average_filter(image, 5)))\n",
    "    FM3 = fm2 - fm3\n",
    "    \n",
    "    return FM1, FM2, FM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61ee7cc-0deb-407c-aebe-646d79c24562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def illumination_features(image):\n",
    "    non_zero_vals = image[image>0]\n",
    "    IM1 = np.mean(non_zero_vals)\n",
    "    IM2 = np.var(non_zero_vals[non_zero_vals<=IM1])\n",
    "    IM3 = np.var(non_zero_vals[non_zero_vals>IM1])    \n",
    "    IM4 = np.var(non_zero_vals)\n",
    "    return IM1, IM2, IM3, IM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80929ec1-9fd0-4415-be94-8cdc1ece0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def contrast_features(image):\n",
    "    hist = cv.calcHist([image.flatten()], [0], None, [16], [1, 256])\n",
    "    ct1 = np.abs(hist/np.sum(hist)-0.0625).sum()\n",
    "    ct2 = (hist==0).sum()\n",
    "    \n",
    "    avgd = moving_average_filter(image, 3)\n",
    "    hist = cv.calcHist([avgd.flatten()], [0], None, [16], [1, 256])\n",
    "    ct3 = np.abs(hist/np.sum(hist)-0.0625).sum()\n",
    "    ct4 = (hist==0).sum()\n",
    "    return ct1, ct2, ct3, ct4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ac4d0c-fe7f-41d2-82e1-03b668a3b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def extract_sift_features(patches):\n",
    "    sift_extractor = cv.SIFT_create()\n",
    "    features = []\n",
    "    for patch in patches:\n",
    "        if patch is None:\n",
    "            return None\n",
    "        kp, des = sift_extractor.detectAndCompute(patch, None)\n",
    "        if des is None: continue\n",
    "        features.append(des)\n",
    "    if len(features) == 0: return None\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19ebe951-ddce-4ac8-adf1-057623238d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def downscale_image(image, max_dim):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    if height <= max_dim and width <= max_dim:\n",
    "        return image\n",
    "    \n",
    "    aspect_ratio = float(height) / float(width)\n",
    "\n",
    "    if height > width:\n",
    "        new_height = max_dim\n",
    "        new_width = int(new_height / aspect_ratio)\n",
    "    else:\n",
    "        new_width = max_dim\n",
    "        new_height = int(new_width * aspect_ratio)\n",
    "\n",
    "    resized_image = cv.resize(image, (new_width, new_height))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "378fa69d-0112-4d31-9443-4d71bed71694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def load_image(img, max_size=400):\n",
    "    if type(img) is str:\n",
    "        img = cv.imread(img, 0)\n",
    "        \n",
    "    if img is None: \n",
    "        return None\n",
    "    \n",
    "    img = downscale_image(img, max_size)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d345111-c96c-4fcc-b248-6041d254a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_image_features(img):\n",
    "    img = load_image(img)\n",
    "    features_ptchs = extract_sift_features([img])\n",
    "    return features_ptchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "868bb062-dbc0-41a2-9acc-ad23a579ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "430b7092-dcfd-4db7-993f-d983227bea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "NUM_CORES = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384e1757-93c9-423e-aeb9-767c03463293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans as KMeans\n",
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "class FeatureGenerator():\n",
    "    \n",
    "    def __init__(self, dataset_path_bow=None, model_name_kmean=None, feature_size=100):\n",
    "        \n",
    "        self.feature_size = feature_size\n",
    "        \n",
    "        if os.path.isfile(model_name_kmean+\"_kmeans.pkl\"):\n",
    "            with open(model_name_kmean+\"_kmeans.pkl\", \"rb\") as f:\n",
    "                self.kmeans = pickle.load(f)\n",
    "                print('Loaded kmeans model')\n",
    "        else:\n",
    "            print('Train kmeans model')\n",
    "            \n",
    "            data = []\n",
    "            if not isinstance(dataset_path_bow, list):\n",
    "                dataset_path_bow = [dataset_path_bow]\n",
    "\n",
    "            for p in dataset_path_bow:\n",
    "                imgs = [im for im in glob.glob(os.path.join(p, '*.png'))]\n",
    "                data.extend(imgs)\n",
    "                imgs = [im for im in glob.glob(os.path.join(p, '*.jpg'))]\n",
    "                data.extend(imgs)\n",
    "                imgs = [im for im in glob.glob(os.path.join(p, '*.jpeg'))]\n",
    "                data.extend(imgs)\n",
    "            \n",
    "            descriptors = []\n",
    "            descriptors = Parallel(n_jobs=NUM_CORES)(delayed(get_image_features)(img) for img in tqdm.tqdm(data))\n",
    "            descriptors = [item for item in descriptors if item is not None]\n",
    "\n",
    "            training_descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "            self.kmeans = KMeans(n_clusters=self.feature_size, \n",
    "                                 random_state=0, \n",
    "                                 batch_size=1024*NUM_CORES).fit(training_descriptors.astype('float'))\n",
    "            \n",
    "            with open(model_name_kmean+'_kmeans.pkl', \"wb\") as f:\n",
    "                pickle.dump(self.kmeans, f)\n",
    "        \n",
    "    def generate_features(self, img, include_generic=True):\n",
    "        \n",
    "        features_ptchs = get_image_features(img)\n",
    "        \n",
    "        histogram = np.zeros(self.feature_size)\n",
    "        if features_ptchs is not None:\n",
    "            for i in range(features_ptchs.shape[0]):\n",
    "                index = self.kmeans.predict([features_ptchs[i].astype('float')])[0]\n",
    "                histogram[index] += 1\n",
    "        \n",
    "        if include_generic:\n",
    "            histogram = np.append(histogram, color_feature(img))\n",
    "            histogram = np.append(histogram, focus_features(img))\n",
    "            histogram = np.append(histogram, contrast_features(img))\n",
    "            histogram = np.append(histogram, illumination_features(img))\n",
    "        \n",
    "        return histogram\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de6c3a9a-3675-4447-bb95-347640f44710",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_bow = [os.path.join(DATASET_PATH, 'processed', '0'), \n",
    "                    os.path.join(DATASET_PATH, 'processed_test', '0'), \n",
    "                    os.path.join(DATASET_PATH, 'processed_test', '1'), \n",
    "                    os.path.join(DATASET_PATH, 'processed_test', '1'), \n",
    "                    os.path.join(DATASET_PATH, 'processed_test', '2'), \n",
    "                    os.path.join(DATASET_PATH, 'processed_test', '2')]\n",
    "dataset_path_bow.extend([im for im in glob.glob(os.path.join(DATASET_PATH, 'trash_images',  '**/*'), recursive=True) if '.' not in im])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01eb5dcc-451a-415f-b7ad-d11c7f57ecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded kmeans model\n",
      "CPU times: user 2.43 ms, sys: 31.8 ms, total: 34.3 ms\n",
      "Wall time: 33.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_gen = FeatureGenerator(dataset_path_bow, 'all_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "472091cc-a625-4b84-a65a-8b245241418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def zoom_augmentation(image, zoom_factor):\n",
    "    height, width = image.shape[:2]\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "    resized_image = cv.resize(image, (new_width, new_height))\n",
    "    top_pad = int((height - new_height) / 2)\n",
    "    bottom_pad = height - new_height - top_pad\n",
    "    left_pad = int((width - new_width) / 2)\n",
    "    right_pad = width - new_width - left_pad\n",
    "    padded_image = cv.copyMakeBorder(resized_image, top_pad, bottom_pad, \n",
    "                                     left_pad, right_pad, cv.BORDER_CONSTANT, value=0)\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad7fc39-71a4-46a7-b6db-c3359ce5b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def random_rotation_augmentation(image, angle_range=(-180, 180)):\n",
    "    # Randomly choose rotation angle\n",
    "    angle = random.uniform(*angle_range)\n",
    "    \n",
    "    # Get image size\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Compute rotation matrix\n",
    "    rotation_matrix = cv.getRotationMatrix2D((width / 2, height / 2), angle, 1.0)\n",
    "    \n",
    "    # Perform rotation\n",
    "    rotated_image = cv.warpAffine(image, rotation_matrix, (width, height))\n",
    "    \n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "703f951a-343f-444d-a0b4-2b0ace2a9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def augument_image(img):\n",
    "    zoom = random.uniform(0.8, 1)\n",
    "    img = zoom_augmentation(img, zoom)\n",
    "    img = random_rotation_augmentation(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3d99a53-553f-4379-80bf-3a729a735617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import hashlib\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, feature_generator):\n",
    "        self.feature_gen = feature_generator\n",
    "        self.data = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def load_data(self, data_paths):\n",
    "        random.seed(42)\n",
    "        random.shuffle(data_paths)\n",
    "        sample = data_paths[0]\n",
    "        x = self.prepare_sample(sample[1], sample[0], False)\n",
    "        hash_str = str(x[0])+str(x[1])+str(x[2])\n",
    "        hash_object = hashlib.md5(hash_str.encode())\n",
    "        model_name = str(hash_object.hexdigest())\n",
    "        \n",
    "        if os.path.isfile(model_name+\"_data.pkl\"):\n",
    "            with open(model_name+\"_data.pkl\", \"rb\") as f:\n",
    "                self.data = pickle.load(f)\n",
    "                print('Loaded data')\n",
    "        else:\n",
    "            print('Generating data')\n",
    "            \n",
    "            result_list = Parallel(n_jobs=NUM_CORES)(delayed(self.prepare_sample)(img_pth, class_id, False) for class_id, img_pth in tqdm.tqdm(data_paths))\n",
    "            result_list = [r for r in result_list if r[0] is not None and r[1] is not None]\n",
    "            self.data.extend(result_list)\n",
    "            \n",
    "            with open(model_name+'_data.pkl', \"wb\") as f:\n",
    "                pickle.dump(self.data, f)\n",
    "    \n",
    "    def prepare_sample(self, img_pth, class_id, augument=True):\n",
    "        img = load_image(img_pth)\n",
    "        if img is None:\n",
    "            return (None, None, None)\n",
    "        if augument:\n",
    "            img = augument_image(img)\n",
    "        features = self.feature_gen.generate_features(img)\n",
    "        return (class_id, features, img_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6e91e46-fe83-40fe-bf82-e8ea2a1202e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os, glob\n",
    "import random\n",
    "\n",
    "class EyeQDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, feature_gen):\n",
    "        super().__init__(feature_gen)\n",
    "        data_paths = []\n",
    "        \n",
    "        if not isinstance(dataset_path, list):\n",
    "            dataset_path = [dataset_path]\n",
    "        \n",
    "        for p in dataset_path:\n",
    "            for i in range(3):\n",
    "                class_i = [(2-i, im) for im in glob.glob(os.path.join(p, str(i), '*.png'))]\n",
    "                data_paths.extend(class_i)\n",
    "        \n",
    "        self.load_data(data_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de1fccbe-9741-4b73-82fe-7b6852bd96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os, glob\n",
    "import random\n",
    "\n",
    "class RandomImages(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, feature_gen):\n",
    "        super().__init__(feature_gen)\n",
    "        data_paths = []\n",
    "        \n",
    "        if not isinstance(dataset_path, list):\n",
    "            dataset_path = [dataset_path]\n",
    "            \n",
    "        for p in dataset_path:\n",
    "            class_i = [(0,im) for im in glob.glob(os.path.join(p,  '**/*.jpg'), recursive=True)]\n",
    "            data_paths.extend(class_i)\n",
    "            class_i = [(0,im) for im in glob.glob(os.path.join(p,  '**/*.jpeg'), recursive=True)]\n",
    "            data_paths.extend(class_i)\n",
    "        \n",
    "        self.load_data(data_paths)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f800fba-9892-41b6-a4c8-8d577877d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DRIMDBDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, feature_gen):\n",
    "        super().__init__(feature_gen)\n",
    "        data_paths = []\n",
    "        \n",
    "        bad_samples = [(0,im) for im in glob.glob(os.path.join(dataset_path, 'Bad', '*.jpg'))]\n",
    "        data_paths.extend(bad_samples)\n",
    "        \n",
    "        good_samples = [(2,im) for im in glob.glob(os.path.join(dataset_path, 'Good', '*.jpg'))]\n",
    "        data_paths.extend(good_samples)\n",
    "        \n",
    "        outlier_samples = [(0, im) for im in glob.glob(os.path.join(dataset_path, 'Outlier', '*.jpg'))]\n",
    "        data_paths.extend(outlier_samples)\n",
    "        \n",
    "        self.load_data(data_paths)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b01183f9-da83-4d88-a7b9-78a74dd01c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "dataset = EyeQDataset([os.path.join(DATASET_PATH, 'processed'), os.path.join(DATASET_PATH, 'processed_test')], feature_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20cf9873-0552-4e95-ab1a-95dd7da56c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "dataset_random = RandomImages(os.path.join(DATASET_PATH, 'trash_images'), feature_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4de0290f-9169-4259-b21a-7cd2a3d501db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "dataset_drimdb = DRIMDBDataset('/home/tiurin/projects/ExampleProject/Temp/DRIMDB', feature_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a718af0-e286-420f-b447-48889c729209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tiurin/projects/ExampleProject/Temp/DRIMDB/Good/drimdb_good (65).jpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_drimdb[10][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59676eef-8e1f-415c-ba51-fd9ef2000972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_dataset(eye=True, random=True, test=False, test_size=0.0, features_range=(0, 112)):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    feature_gen = FeatureGenerator([], 'all_data')\n",
    "    \n",
    "    if eye:\n",
    "        dataset = EyeQDataset([os.path.join(DATASET_PATH, 'processed'), os.path.join(DATASET_PATH, 'processed_test')], feature_gen)\n",
    "        X.extend([d[1][features_range[0]:features_range[1]] for d in dataset.data])\n",
    "        y.extend([d[0] for d in dataset.data])\n",
    "    if random:\n",
    "        dataset_random = RandomImages(os.path.join(DATASET_PATH, 'trash_images'), feature_gen)\n",
    "        X.extend([d[1][features_range[0]:features_range[1]] for d in dataset_random.data])\n",
    "        y.extend([d[0] for d in dataset_random.data])\n",
    "    if test:\n",
    "        dataset_drimdb = DRIMDBDataset('/home/tiurin/projects/ExampleProject/Temp/DRIMDB', feature_gen)\n",
    "        X.extend([d[1][features_range[0]:features_range[1]] for d in dataset_drimdb.data])\n",
    "        y.extend([d[0] for d in dataset_drimdb.data])\n",
    "    \n",
    "    if test_size > 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b46975eb-ef1b-4d91-94af-2823fce9a1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/share/data_rechenknecht03_2/students/tiurin/projects/ExampleProject/Temp/code/nbs/dataset.ipynb'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "ipynb_path = os.path.join(os.getcwd(), 'dataset.ipynb')\n",
    "ipynb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "961d6d50-94bd-4c5b-8ade-89291f040ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataset\n",
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export(ipynb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51a6f9-30e1-41c9-bab2-28b9071f43f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mri_gpu] *",
   "language": "python",
   "name": "conda-env-mri_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
